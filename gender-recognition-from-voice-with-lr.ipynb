{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb5dab711d24000faa6fa19bad96668b4ff55613"
   },
   "source": [
    "## INTRODUCTION\n",
    "\n",
    "### In this notebook, gender will be predicted with Logistic Regression algorithm. I will apply this algorithm by hand, I won't use scikit-learn library directly.\n",
    "The steps of the work is below\n",
    "\n",
    "**1. EDA(Expolatory Data Analysis) for the Gender Recognition by Voice dataset**\n",
    "\n",
    "   * [Getting familiar with the dataset](#get-familiar)\n",
    "    \n",
    "**2. Normalization (If needed)**\n",
    "\n",
    "* [Normalization](#normalization)\n",
    "\n",
    "**3. Logistic Regression implementation with python (Scikit-learn library will be used different parts of the algorithm)**\n",
    "\n",
    "* [Choosing train-test split randomly](#traintest)\n",
    "\n",
    "* [Initialize Parameters (w,b)](#initparam)\n",
    "\n",
    "* [Implementing Sigmoid function](#sigmoid)\n",
    "\n",
    "* [Calculation of cost-loss function](#cost)\n",
    "\n",
    "* [Forward-Backward function](#fb)\n",
    "\n",
    "* [Purpose of the Derivation *-(Optimization)*](#derivation)\n",
    "\n",
    "* [Updating Weight and Bias](#update)\n",
    "\n",
    "* [Prediction](#predict)\n",
    "\n",
    "* [Logistic Regression](#lr)\n",
    "\n",
    "* [Interpreting the result via visualization](#visualization)\n",
    "\n",
    "**[References](#references)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5daa49fe3f9b180de30681ab31bfaa391b01179a"
   },
   "source": [
    "<a id=\"get-familiar\"></a> <br>\n",
    "## Getting familiar with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      "meanfreq    3168 non-null float64\n",
      "sd          3168 non-null float64\n",
      "median      3168 non-null float64\n",
      "Q25         3168 non-null float64\n",
      "Q75         3168 non-null float64\n",
      "IQR         3168 non-null float64\n",
      "skew        3168 non-null float64\n",
      "kurt        3168 non-null float64\n",
      "sp.ent      3168 non-null float64\n",
      "sfm         3168 non-null float64\n",
      "mode        3168 non-null float64\n",
      "centroid    3168 non-null float64\n",
      "meanfun     3168 non-null float64\n",
      "minfun      3168 non-null float64\n",
      "maxfun      3168 non-null float64\n",
      "meandom     3168 non-null float64\n",
      "mindom      3168 non-null float64\n",
      "maxdom      3168 non-null float64\n",
      "dfrange     3168 non-null float64\n",
      "modindx     3168 non-null float64\n",
      "label       3168 non-null object\n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('voice.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68fa26923ebae1d39b56a2e5487fb1c523482637"
   },
   "source": [
    "***IS THERE ANY MISSING FEATURE VALUE?***\n",
    "\n",
    "We can see that, there is no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "6bd9493004702dd0bd213e2edba6a093baf76bfd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.079557</td>\n",
       "      <td>0.119090</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>0.209592</td>\n",
       "      <td>0.141634</td>\n",
       "      <td>1.932562</td>\n",
       "      <td>8.308895</td>\n",
       "      <td>0.963181</td>\n",
       "      <td>0.738307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132786</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.298222</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.726562</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>0.125160</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>0.160106</td>\n",
       "      <td>0.092899</td>\n",
       "      <td>0.205718</td>\n",
       "      <td>0.112819</td>\n",
       "      <td>1.530643</td>\n",
       "      <td>5.987498</td>\n",
       "      <td>0.967573</td>\n",
       "      <td>0.762638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150762</td>\n",
       "      <td>0.105945</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.479620</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.312500</td>\n",
       "      <td>5.304688</td>\n",
       "      <td>0.123992</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.076767</td>\n",
       "      <td>0.144337</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.231962</td>\n",
       "      <td>0.121430</td>\n",
       "      <td>1.397156</td>\n",
       "      <td>4.766611</td>\n",
       "      <td>0.959255</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>0.301339</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.283937</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.078018</td>\n",
       "      <td>0.138587</td>\n",
       "      <td>0.088206</td>\n",
       "      <td>0.208587</td>\n",
       "      <td>0.120381</td>\n",
       "      <td>1.099746</td>\n",
       "      <td>4.070284</td>\n",
       "      <td>0.970723</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142239</td>\n",
       "      <td>0.096729</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.336476</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.164062</td>\n",
       "      <td>2.156250</td>\n",
       "      <td>0.148272</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.121451</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.201957</td>\n",
       "      <td>0.126377</td>\n",
       "      <td>1.190368</td>\n",
       "      <td>4.787310</td>\n",
       "      <td>0.975246</td>\n",
       "      <td>0.804505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134329</td>\n",
       "      <td>0.105881</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.340365</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.695312</td>\n",
       "      <td>4.679688</td>\n",
       "      <td>0.089920</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "5  0.132786  0.079557  0.119090  0.067958  0.209592  0.141634   1.932562   \n",
       "6  0.150762  0.074463  0.160106  0.092899  0.205718  0.112819   1.530643   \n",
       "7  0.160514  0.076767  0.144337  0.110532  0.231962  0.121430   1.397156   \n",
       "8  0.142239  0.078018  0.138587  0.088206  0.208587  0.120381   1.099746   \n",
       "9  0.134329  0.080350  0.121451  0.075580  0.201957  0.126377   1.190368   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...    centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...    0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...    0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...    0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...    0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...    0.135120  0.106398  0.016931   \n",
       "5     8.308895  0.963181  0.738307  ...    0.132786  0.110132  0.017112   \n",
       "6     5.987498  0.967573  0.762638  ...    0.150762  0.105945  0.026230   \n",
       "7     4.766611  0.959255  0.719858  ...    0.160514  0.093052  0.017758   \n",
       "8     4.070284  0.970723  0.770992  ...    0.142239  0.096729  0.017957   \n",
       "9     4.787310  0.975246  0.804505  ...    0.134329  0.105881  0.019300   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "5  0.253968  0.298222  0.007812  2.726562  2.718750  0.125160   male  \n",
       "6  0.266667  0.479620  0.007812  5.312500  5.304688  0.123992   male  \n",
       "7  0.144144  0.301339  0.007812  0.539062  0.531250  0.283937   male  \n",
       "8  0.250000  0.336476  0.007812  2.164062  2.156250  0.148272   male  \n",
       "9  0.262295  0.340365  0.015625  4.695312  4.679688  0.089920   male  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 records in the dataset\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b153dda80b3f27ec8fe82716aca6f88bc71d82ca"
   },
   "source": [
    "***TRANSLATE MALE-FEMALE OPTIONS TO COMPUTER'S LANGUAGE***\n",
    "\n",
    "In order to make train,test, and prediction, we have to convert our binary male-female option into 0-1's. I choose male as '0' and female as '1'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "293f9afd5cca6c5b874d8bde1915b5eab4e70c78"
   },
   "outputs": [],
   "source": [
    "data.label = [1 if each=='female' else 0 for each in data.label]\n",
    "# Our y-axis(Outcome)\n",
    "y = data.label.values\n",
    "# Our features for prediction&training, x will include all of data except the outcome(label)\n",
    "x_data = data.drop([\"label\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5e00a570a3b0292fe9ddc635d18ec5bc59c2bd2"
   },
   "source": [
    " <a id=\"normalization\"></a> <br>\n",
    " ## NORMALIZATION\n",
    "\n",
    "Normalization have to applied to dataset, because some features can brake the balance with their proportion to other features like kurtosis and skew. These attributes should be re-scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "6e6b57748e262d4de9ed0c014665ad084a8de7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.kurt of    meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
      "0  0.096419  0.473409  0.084125  0.060063  0.204956  0.254828  0.367853   \n",
      "1  0.125828  0.505075  0.116900  0.077635  0.215683  0.246961  0.644279   \n",
      "2  0.179222  0.675536  0.102873  0.034284  0.385912  0.457148  0.885255   \n",
      "3  0.528261  0.554611  0.587559  0.389906  0.715802  0.407358  0.031549   \n",
      "4  0.452195  0.627209  0.454272  0.317627  0.707515  0.474474  0.027742   \n",
      "\n",
      "       kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
      "0  0.208279  0.635798  0.564526  0.000000  0.096419  0.157706  0.030501   \n",
      "1  0.483766  0.630964  0.591578  0.000000  0.125828  0.287642  0.031140   \n",
      "2  0.782275  0.442738  0.548382  0.000000  0.179222  0.236945  0.030264   \n",
      "3  0.001613  0.923261  0.856457  0.299565  0.528261  0.183442  0.041287   \n",
      "4  0.001732  0.958736  0.926348  0.372362  0.452195  0.279190  0.036829   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
      "0  0.981526  0.000000  0.006452  0.000000  0.000000  0.000000  \n",
      "1  0.834600  0.000407  0.006452  0.002144  0.002146  0.056449  \n",
      "2  0.954963  0.000060  0.006452  0.000357  0.000358  0.049885  \n",
      "3  0.834600  0.065659  0.006452  0.025375  0.025393  0.265043  \n",
      "4  0.929285  0.238994  0.006452  0.250536  0.250715  0.223380  >\n"
     ]
    }
   ],
   "source": [
    "# Find the max&min value of the each column then apply the formula. This is a way to re-scaling\n",
    "x = (x_data -np.min(x_data))/(np.max(x_data)-np.min(x_data)).values\n",
    "print(x.head().kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb030cada6e4c86b0a24a5baf32d3fca3a52bd3f"
   },
   "source": [
    "## Logistic Regression Steps\n",
    "\n",
    "Logistic Regression Algorithm's steps are represented below in computation graph way:\n",
    "\n",
    "![](https://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression_files/logistic_regression_schematic.png)\n",
    "*Source: [https://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression_files/logistic_regression_schematic.png](http://)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ce3d525c69012daf0f9d77afb73bc78783b0e31"
   },
   "source": [
    " <a id=\"traintest\"></a> <br>\n",
    " ## TRAIN TEST SPLIT\n",
    "\n",
    "20% of the data will be used for the test, rest of the data will be used for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "22b9728418ae61b4621f6ac4a9c339aa73b02dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (20, 2534)\n",
      "x_test:  (20, 634)\n",
      "y_train:  (2534,)\n",
      "y_test:  (634,)\n"
     ]
    }
   ],
   "source": [
    "# Select Train-Test split randomly every-time\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "x_train=x_train.T\n",
    "x_test=x_test.T\n",
    "y_train=y_train.T\n",
    "y_test=y_test.T\n",
    "\n",
    "# Features - Records\n",
    "print(\"x_train: \",x_train.shape)\n",
    "print(\"x_test: \",x_test.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24e80171d9c03ee4302e17f7bebe53431cb8e069"
   },
   "source": [
    "<a id=\"initparam\"></a> <br>\n",
    "## Initializing Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "6384b7398b65034eec1d2bee544aaed5da8ab5bd"
   },
   "outputs": [],
   "source": [
    "# Initialize Parameters(dimensin = count of the features)\n",
    "def initialize_weight_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b=0.0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d5caabad248ca0952cefa8221a09057b52e450dc"
   },
   "source": [
    "<a id=\"sigmoid\"></a> <br>\n",
    "## IMPLEMENTING SIGMOID FUNCTION\n",
    "\n",
    "Sigmoid function is the one of the magical function from the mathland. It scales our data to probabilistic values. All of data will be represented in between 0 and 1 correctly. \n",
    "After the implementation we can check the correctness the function f(0)=0.5. \n",
    "Here is the graph and formula of the sigmoid function.\n",
    "\n",
    "![](https://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression_files/logistic_function.png)\n",
    "\n",
    "*Figure1 : https://rasbt.github.io/mlxtend/user_guide/classifier/LogisticRegression_files/logistic_function.png*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1c1e456ebba362167d87629c79a513e8139706f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid function\n",
    "# Calculation of z\n",
    "# z = np.dot(w.T,x_train)+b\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "# test\n",
    "print(sigmoid(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c15b0a826c586526fc7fc16dbe53cfd8cb332e8"
   },
   "source": [
    "<a id=\"cost\"></a> <br>\n",
    "## Cost/Loss Function\n",
    "We want to minimize the cost, hence we will take derivative of the funvtion then, when the derivative equal to zero the root of the function gives to minimum value. \n",
    "\n",
    "![](http://image.ibb.co/dFCR3H/6.jpg)\n",
    "Figure 3 : Loss function **(Cross Entropy Formula)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "0b702a11f8f7ebd21ad5ff02a7be233002fe2b5d"
   },
   "outputs": [],
   "source": [
    "# Forward and Backward Propogarion Combined\n",
    "def ForwardBackwardP(w,b,x_train,y_train):\n",
    "    #Forward Propogation\n",
    "    z = np.dot(w.T,x_train)+b # Multiply with weight then sum each data\n",
    "    y_head = sigmoid(z) # Scale the result into a probablistic value\n",
    "    \n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    # Cost is summation of all losses\n",
    "    cost = (np.sum(loss))/x_train.shape[1] # x_train.shape[1] is count of the samples\n",
    "    # Divided to sample size because of scaling\n",
    "    \n",
    "    # Backward Propogation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1]\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]\n",
    "    # Save into Dictionary\n",
    "    gradients = {\"derivative_weight\":derivative_weight,\"derivative_bias\":derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7a7caa421d1ecb221e82d4c20734b257ceb7424"
   },
   "source": [
    "<a id=\"derivation\"></a> <br>\n",
    "## PURPOSE OF THE DERIVATION\n",
    "\n",
    "![](http://image.ibb.co/dAaYJH/7.jpg)\n",
    "Figure 4 : Purpose of the Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c85748c4aa41c9870e6440a09e2e864f357e1b3"
   },
   "source": [
    "<a id=\"update\"></a> <br> \n",
    "# Update Learning Parameters (Weights and Bias)\n",
    "\n",
    "Algorithm should update the weights and bias by number of iterations. While we doing this, we will use **learning_rate parameter** It is coefficient of derivatives and it is a *hyperparameter*. So it means we should tune value of the paramter by manually.\n",
    "\n",
    "![](http://image.ibb.co/hYTTJH/8.jpg)\n",
    "> Alpha value = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d2b902bc0e678530490f1c74757a7840941aa893"
   },
   "outputs": [],
   "source": [
    "# Updating Learning Parameters(wi,b)\n",
    "def update(w,b,x_train,y_train,learning_rate,iterations):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    \n",
    "    # Updating learning parameters by number of iterations\n",
    "    for i in range(iterations):\n",
    "        # Make forward and backward propogation and find cost and gradients\n",
    "        cost,gradients = ForwardBackwardP(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        #UPDATE\n",
    "        w = w- learning_rate*gradients[\"derivative_weight\"]\n",
    "        b = b- learning_rate*gradients[\"derivative_bias\"]\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print(\"Cost after iteration %i: %f\" %(i,cost))\n",
    "            \n",
    "        # Update learn parameters and bias\n",
    "        parameters = {\"weight\":w,\"bias\":b}\n",
    "        \n",
    "    # Plot\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b66a0701839400b9ffd4c4c50eaaaa056ad2643b"
   },
   "source": [
    "<a id=\"predict\"></a> <br>\n",
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "9f9e5bc84a2c57ec349c08f33c833f1de31537c4"
   },
   "outputs": [],
   "source": [
    "def predict(w,b,x_test):\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b) # Forward propogation for x_test\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    \n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<=0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "    return Y_prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59ca8977885aaa029a6669d52c14ba845f258607"
   },
   "source": [
    "<a id=\"lr\"></a> <br>\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "4a5a3d28c137033349205627ba3c52439c5c399b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692360\n",
      "Cost after iteration 10: 0.570539\n",
      "Cost after iteration 20: 0.510995\n",
      "Cost after iteration 30: 0.472210\n",
      "Cost after iteration 40: 0.442623\n",
      "Cost after iteration 50: 0.418237\n",
      "Cost after iteration 60: 0.397345\n",
      "Cost after iteration 70: 0.379065\n",
      "Cost after iteration 80: 0.362863\n",
      "Cost after iteration 90: 0.348376\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 90.60773480662984 %\n",
      "test accuracy: 92.74447949526814 %\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train,y_train,x_test,y_test,learning_rate,iterations):\n",
    "    # Initialize \n",
    "    dimension = x_train.shape[0] # Feature size\n",
    "    w,b = initialize_weight_and_bias(dimension)\n",
    "    \n",
    "    parameters, gradients, cost_list = update(w,b,x_train,y_train,learning_rate,iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n",
    "    \n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "    return y_prediction_test\n",
    "    \n",
    "y_pred_test = logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, iterations = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "9959c850505493f09aab0acd7bc768ed5cce682c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Male', 'Female', 'Female', 'Male']\n",
      "['Female', 'Male', 'Male', 'Female', 'Female', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Female', 'Male']\n"
     ]
    }
   ],
   "source": [
    "# Top 20 prediction and real values\n",
    "head_y_pred= [\"Female\" if each == 1 else \"Male\" for each in y_pred_test[0][:20]]\n",
    "head_y_real = [\"Female\" if each == 1 else \"Male\" for each in y_test[:20]]\n",
    "print(head_y_pred)\n",
    "print(head_y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82fcceea1869b2feec67dce67931033b56b02e54"
   },
   "source": [
    "<a id=\"visualization\"></a> <br>\n",
    "# Visualization\n",
    "## Rate of the Male-Female Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "11128c56d1474d0883e85ef747960c6543018017"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "labels": [
          "Male",
          "Female"
         ],
         "type": "pie",
         "uid": "12ba181d-f5ac-4938-aca6-b09676bd17fd",
         "values": [
          367,
          267
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"a4c7900f-8bbc-4912-b34b-dc7a0ab42307\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a4c7900f-8bbc-4912-b34b-dc7a0ab42307\", [{\"labels\": [\"Male\", \"Female\"], \"values\": [367, 267], \"type\": \"pie\", \"uid\": \"aeadaaad-3df8-4870-9d60-e71e0796ffd4\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"a4c7900f-8bbc-4912-b34b-dc7a0ab42307\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"a4c7900f-8bbc-4912-b34b-dc7a0ab42307\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"a4c7900f-8bbc-4912-b34b-dc7a0ab42307\", [{\"labels\": [\"Male\", \"Female\"], \"values\": [367, 267], \"type\": \"pie\", \"uid\": \"aeadaaad-3df8-4870-9d60-e71e0796ffd4\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"a4c7900f-8bbc-4912-b34b-dc7a0ab42307\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count of male-female\n",
    "male_count = 0 \n",
    "female_count = 0\n",
    "for i in range(y_pred_test.shape[1]):\n",
    "    if y_pred_test[0][i] == 0:\n",
    "        male_count+=1\n",
    "    else:\n",
    "        female_count+=1\n",
    "\n",
    "# Visualization\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "labels = ['Male','Female']\n",
    "values = [male_count,female_count]\n",
    "\n",
    "trace = go.Pie(labels=labels, values=values)\n",
    "\n",
    "py.iplot([trace], filename='basic_pie_chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "606fcf8ce157a4bcbd540c6f3b56176016adb2eb"
   },
   "source": [
    "## Rate of male-female for real test data\n",
    "We can see accuracy of the our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "8a177d5ae783642c332a93f2ad81c05450248da9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "labels": [
          "Male",
          "Female"
         ],
         "type": "pie",
         "uid": "d92b6e24-1f11-4594-974e-96fc8e78708a",
         "values": [
          337,
          297
         ]
        }
       ],
       "layout": {}
      },
      "text/html": [
       "<div id=\"bfa26bff-8015-4bd8-afdb-65818360e0a9\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bfa26bff-8015-4bd8-afdb-65818360e0a9\", [{\"labels\": [\"Male\", \"Female\"], \"values\": [337, 297], \"type\": \"pie\", \"uid\": \"f51bc6f5-5582-422c-a92c-03b323267478\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"bfa26bff-8015-4bd8-afdb-65818360e0a9\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"bfa26bff-8015-4bd8-afdb-65818360e0a9\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bfa26bff-8015-4bd8-afdb-65818360e0a9\", [{\"labels\": [\"Male\", \"Female\"], \"values\": [337, 297], \"type\": \"pie\", \"uid\": \"f51bc6f5-5582-422c-a92c-03b323267478\"}], {}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"bfa26bff-8015-4bd8-afdb-65818360e0a9\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculation of rate of raw test data\n",
    "male_test=0\n",
    "female_test=0\n",
    "for i in y_test:\n",
    "    if i == 0:\n",
    "        male_test+=1\n",
    "    else:\n",
    "        female_test+=1\n",
    "\n",
    "values = [male_test,female_test]\n",
    "trace = go.Pie(labels=labels, values=values)\n",
    "py.iplot([trace], filename='basic_pie_chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0145df589c2314b442f9602b9014ba53ca3bb5b1"
   },
   "source": [
    "<a id=\"references\"></a> <br>\n",
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48d76ded96eb4b2b07b8ab838931929fcf9d6731"
   },
   "source": [
    "*  References : This work is includes some parts of 'kanncaa1's deep-learning kernel. Thanks for sharing.*\n",
    "*  Source: https://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
